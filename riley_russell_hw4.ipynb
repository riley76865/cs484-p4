{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 484 :: Data Mining :: George Mason University :: Spring 2023\n",
    "\n",
    "\n",
    "# Homework 4: Recommender Systems\n",
    "\n",
    "- **100 points [9% of your final grade]**\n",
    "- **Due Sunday, April 30 by 11:59pm**\n",
    "\n",
    "- *Goals of this homework:* implement the Matrix Factorization algorithm.\n",
    "\n",
    "- *Submission instructions:* for this homework, you only need to submit to Blackboard. Please name your submission **FirstName_Lastname_hw4.ipynb**, so for example, my submission would be something like **Ziwei_Zhu_hw4.ipynb**. Your notebook should be fully executed so that we can see all outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Matrix Factorization (100 points total)\n",
    "\n",
    "For this part, we will:\n",
    "\n",
    "* load and process the MovieLens 1M dataset, \n",
    "* build a matrix factorization model,\n",
    "* evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out, we need to prepare the data. We will use the MovieLens 1M data from https://grouplens.org/datasets/movielens/1m/ in this homework. Lucky for you, we are providing the file containing the ratings -- ratings.dat  -- so all you need to do is loading the ratings.dat file in the notebook as a DataFrame variable using the Pandas library. The code to do this has been provided in the next cell, but you need to run it. The DataFrame variable is named as 'data_df'. The code names the column of movie id as 'MovieID', names the column of user id as 'UserID', names the column of rating as 'Rating', and the column of timestamp as 'Timestamp'. After this, the first 5 rows of data_df are printed out by DataFrame.head().\n",
    "\n",
    "Note that you should install the pandas library before you use it. For more information about Pandas, here is a quick introduction: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.read_csv('./ratings.dat', sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], engine='python')\n",
    "data_df.head()\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find some simple statistics for this dataset. In the next cell, please count and print how many unique users, unique movies, and how many ratings there are in this dataset. \n",
    "\n",
    "**Hint: You may need to use the function pandas.Series.unique().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users: 6040\n",
      "Unique Movies: 3706\n",
      "Ratings: 1000209\n"
     ]
    }
   ],
   "source": [
    "# count and print how many unique users, unique movies, and ratings in this dataset\n",
    "# Your Code Here...\n",
    "unique_users = data_df['UserID'].unique()\n",
    "num_unique_users = len(unique_users)\n",
    "print(f'Unique Users: {num_unique_users}')\n",
    "\n",
    "unique_movies = data_df['MovieID'].unique()\n",
    "num_unique_movies = len(unique_movies)\n",
    "print(f'Unique Movies: {num_unique_movies}')\n",
    "\n",
    "ratings = data_df['Rating']\n",
    "num_ratings = len(ratings)\n",
    "print(f'Ratings: {num_ratings}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because in Python, the index for a list starts from 0, it is more convenient if we have the ids of users and movies start from 0 as well. Moreover, we also need to make sure the UserID and MovieID are continuous, so in the next cell, we reindex UserID and MovieID. The code is already provided, but you still need to run it. (It may take a few minutes to run it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000209/1000209 [00:59<00:00, 16928.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       0        0       5  978300760\n",
       "1       0        1       3  978302109\n",
       "2       0        2       3  978301968\n",
       "3       0        3       4  978300275\n",
       "4       0        4       5  978824291"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# First, generate dictionaries for mapping old id to new id for users and movies\n",
    "unique_MovieID = data_df['MovieID'].unique()\n",
    "unique_UserID = data_df['UserID'].unique()\n",
    "j = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in unique_UserID:\n",
    "    user_old2new_id_dict[u] = j\n",
    "    j += 1\n",
    "j = 0\n",
    "movie_old2new_id_dict = dict()\n",
    "for i in unique_MovieID:\n",
    "    movie_old2new_id_dict[i] = j\n",
    "    j += 1\n",
    "    \n",
    "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
    "for j in tqdm(range(len(data_df))):\n",
    "    data_df.at[j, 'UserID'] = user_old2new_id_dict[data_df.at[j, 'UserID']]\n",
    "    data_df.at[j, 'MovieID'] = movie_old2new_id_dict[data_df.at[j, 'MovieID']]\n",
    "\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you have got a ready-to-use dataset. The next step is to split it **randomly** into training and testing sets so that you can build your recommendation model based on the training set and evaluate it on the testing set. Here you need to split the data_df into two parts: a DataFrame **train_df** containing 70% user-movie-rating samples in data_df, and a DataFrame **test_df** containing 30% samples. train_df and test_df should have no overlap. In the next cell, write your code and print the numbers of samples in the generated train_df and test_df at last.\n",
    "\n",
    "**Note that here we just have training and testing sets without using a validation set for the sake of simplicity. This is not a good paradigm in practice.**\n",
    "\n",
    "**Hint: you may need to use functions from numpy.random for generating random numbers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_df = 700146\n",
      "num of test_df = 300063\n"
     ]
    }
   ],
   "source": [
    "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
    "# Your Code Here...\n",
    "\n",
    "training_size = int(np.round(0.7 * data_df.shape[0])) # take 70% of rows, rounded to nearest int\n",
    "test_size = data_df.shape[0] - training_size # take remaining rounded 30% of rows\n",
    "\n",
    "training_indicies = list(np.random.choice(np.arange(data_df.shape[0]),size=training_size,replace=False))\n",
    "\n",
    "train_df = data_df.iloc[training_indicies]\n",
    "test_df = data_df.drop(training_indicies)\n",
    "# End of your code\n",
    "\n",
    "print('num of train_df = ' + str(len(train_df)))\n",
    "print('num of test_df = ' + str(len(test_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we need to generate numpy array variables (i.e., matrix version of dataset) for both train_df and test_df for the ease of calculation in the next step. More specifically, we will generate two numpy array variables of size (#user, #movie) with each entry representing the user-movie rating. And if the user-movie rating is missing, then the corresponding entry is 0. The code is already provided, but you still need to run it and it is a good chance for you to check the correctness of your previous code by running the provided code. \n",
    "\n",
    "**Hint: Please make sure you have already installed the scipy library before running the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "num_user = len(data_df['UserID'].unique())\n",
    "num_movie = len(data_df['MovieID'].unique())\n",
    "\n",
    "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), \n",
    "                       shape=(num_user, num_movie)).toarray().astype(float)\n",
    "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), \n",
    "                      shape=(num_user, num_movie)).toarray().astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the processed data, let's implement the matrix factorization (MF for short) model introduced in class. The MF model can be mathematically represented as: \n",
    "\n",
    "$\\underset{\\mathbf{P},\\mathbf{Q}}{\\text{min}}\\,\\,L=\\sum_{(u,i)\\in\\mathcal{O}}(\\mathbf{P}_u\\cdot\\mathbf{Q}^\\top_i-r_{u,i})^2+\\lambda(\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}+\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}})$\n",
    "    \n",
    "where $\\mathbf{P}$ is the user latent factor matrix of size (#user, #latent); $\\mathbf{Q}$ is the movie latent factor matrix of size (#movie, #latent); $\\mathcal{O}$ is a user-movie pair set containing all user-movie pairs having ratings in train_mat; $r_{u,i}$ represents the rating for user u and movie i; $\\lambda(\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}+\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}})$ is the regularization term to overcome overfitting problem, $\\lambda$ is the regularization weight (a hyper-parameter manually set by developer, i.e., you), and $\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}=\\sum_{x}\\sum_{y}(\\mathbf{P}_{x,y})^2$, $\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}}=\\sum_{x}\\sum_{y}(\\mathbf{Q}_{x,y})^2$. Such an L function is called the **loss function** for the matrix factorization model. The goal of training an MF model is to find appropriate $\\mathbf{P}$ and $\\mathbf{Q}$ to minimize the loss L."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement such an MF, here we will write a Python class for the model. There are three functions in this MF class: init, train, and predict. \n",
    "\n",
    "* The 'init' function (**already provided**) is to initialize the variables the MF class needs, which takes 5 inputs: train_mat, test_mat, latent, lr, and reg. 'train_mat' and 'test_mat' are the corresponfing training and testing matrices we have. 'latent' represents the latent dimension we set for the MF model. 'lr' represents the learning rate, i.e., the update step in each optimization iteration, default is 0.01. 'reg' represents the regularization weight, i.e., the $\\lambda$ in the MF formulation.\n",
    "\n",
    "* The 'train' function (**partially provided and need to complete**) is to train the MF model given the training data train_mat. There is only one input to this function: an int variable 'epoch' to indicate how many epochs for training the model. The main body of this function should be a loop for 'epoch' iterations. In each iteration, following the algorithm to update the MF model:\n",
    "\n",
    "        1. Randomly shuffle training user-movie pairs  (i.e., user-movie pairs having ratings in train_mat)\n",
    "        2. Have an inner loop to iterate each user-movie pair:\n",
    "                a. given a user-movie pair (u,i), update the user latent factor and movie latent factor by gradient decsent:    \n",
    "$\\mathbf{P}^\\prime_u=\\mathbf{P}_u-\\gamma [2(\\mathbf{P}_u\\cdot\\mathbf{Q}_i^\\top-r_{u,i})\\cdot\\mathbf{Q}_i+2\\lambda\\mathbf{P}_u]$    \n",
    "$\\mathbf{Q}^\\prime_i=\\mathbf{Q}_i-\\gamma [2(\\mathbf{P}_u\\cdot\\mathbf{Q}_i^\\top-r_{u,i})\\cdot\\mathbf{P}_u+2\\lambda\\mathbf{Q}_i]$ \n",
    "\n",
    "\n",
    "where $\\mathbf{P}_u$ and $\\mathbf{Q}_i$ are row vectors of size (1, #latent), $\\gamma$ is learning rate (default is 0.01), $\\lambda$ is regularization weight.$\n",
    "        \n",
    "        3. After iterating over all user-movie pairs, we have finished the training for the current epoch. Now calculate and print out the value of the loss function L after this epoch, and the RMSE on test_mat by the current MF model. Then append them to lists to keep a record of them.\n",
    "The train function needs to return two lists: 'epoch_loss_list' recording the loss after each training epoch, and 'epoch_test_RMSE_list' recording the RMSE on test_mat after each training epoch. The calculation of RMSE can be represetned as:\n",
    "$$RMSE=\\sqrt{\\frac{1}{|\\mathcal{O}_{test}|}\\sum_{(u,i)\\in\\mathcal{O}_{test}}(\\mathbf{P}_u\\cdot\\mathbf{Q}^\\top_i-r_{u,i})^2}$$ \n",
    "\n",
    "where $\\mathcal{O}_{test}$ is a user-movie pair set containing all user-movie pairs having ratings in test_mat, and $|\\mathcal{O}_{test}|$ represents the total number of user-movie pairs in test_mat.\n",
    "\n",
    "* The 'predict' function (**already provided**) is to calculate the prediction_mat by the learned $\\mathbf{P}$ and $\\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we provide the 'init' and 'predict' functions. You will need to fill in the 'train' function based on the description above. \n",
    "\n",
    "**NOTE that you should not delete or modify the provided code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def __init__(self, train_mat, test_mat, latent=5, lr=0.01, reg=0.01):\n",
    "        self.train_mat = train_mat  # the training rating matrix of size (#user, #movie)\n",
    "        self.test_mat = test_mat  # the training rating matrix of size (#user, #movie)\n",
    "        \n",
    "        self.latent = latent  # the latent dimension\n",
    "        self.lr = lr  # learning rate\n",
    "        self.reg = reg  # regularization weight, i.e., the lambda in the objective function\n",
    "        \n",
    "        self.num_user, self.num_movie = train_mat.shape\n",
    "        \n",
    "        self.sample_user, self.sample_movie = self.train_mat.nonzero()  # get the user-movie paris having ratings in train_mat\n",
    "        self.num_sample = len(self.sample_user)  # the number of user-movie pairs having ratings in train_mat\n",
    "\n",
    "        self.train_indicator_mat = 1.0 * (train_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in train_mat\n",
    "        self.test_indicator_mat = 1.0 * (test_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in test_mat\n",
    "\n",
    "        self.P = np.random.random((self.num_user, self.latent))  # latent factors for users, size (#user, self.latent), randomly initialized\n",
    "        self.Q = np.random.random((self.num_movie, self.latent))  # latent factors for users, size (#movie, self.latent), randomly initialized\n",
    "\n",
    "    def train(self, epoch=20, verbose=True):\n",
    "        \"\"\"\n",
    "        Goal: Write your code to train your matrix factorization model for epoch iterations in this function\n",
    "        Input: epoch -- the number of training epoch \n",
    "        Output: epoch_loss_list -- a list recording the training loss for each epoch\n",
    "                epoch_test_RMSE_list -- a list recording the testing RMSE after each training epoch\n",
    "        \"\"\"\n",
    "        epoch_loss_list = []\n",
    "        epoch_test_RMSE_list = []\n",
    "        for ep in tqdm(range(epoch)):\n",
    "            \"\"\" \n",
    "            Write your code here to implement the training process for one epoch, \n",
    "            and at the end of each epoch, print out the epoch number, the training loss after this epoch, \n",
    "            and the test RMSE after this epoch\n",
    "            \"\"\"\n",
    "            # start of your code\n",
    "            shuffle_users, shuffle_movies = np.nonzero(self.train_mat)\n",
    "            shuffle_pairs = list(zip(shuffle_users,shuffle_movies))\n",
    "            np.random.shuffle(shuffle_pairs)\n",
    "\n",
    "            for user,movie  in shuffle_pairs:\n",
    "                self.P[user] =self.P[user] - self.lr * (2 * np.dot((np.dot(self.P[user],self.Q[movie].T)-self.train_mat[user,movie]),self.Q[movie])+2*self.reg*self.P[user])\n",
    "                self.Q[movie]=self.Q[movie] -self.lr * (2 * np.dot((np.dot(self.P[user],self.Q[movie].T)-self.train_mat[user,movie]),self.P[user])+ 2*self.reg*self.Q[movie])\n",
    "\n",
    "            test_user, test_movie = np.nonzero(test_mat)\n",
    "            test_pairs = list(zip(test_user,test_movie))\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            error = 0\n",
    "            for user,movie in test_pairs:\n",
    "                error += (self.test_mat[user,movie]-np.dot(self.P[user],self.Q[movie]))**2\n",
    "            test_rmse = np.sqrt(error/len(test_pairs))\n",
    "            for user,movie in shuffle_pairs:\n",
    "                epoch_loss += (np.dot(self.P[user],self.Q[movie])-self.train_mat[user,movie])**2\n",
    "            epoch_loss += self.reg * (np.linalg.norm(self.P,ord='fro')+np.linalg.norm(self.Q,ord='fro'))\n",
    "\n",
    "\n",
    "            # End of your code for this function\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            epoch_test_RMSE_list.append(test_rmse)\n",
    "            if verbose:\n",
    "                print('Epoch={0}, Training Loss={1}, Testing RMSE={2}'.format(ep + 1, epoch_loss, test_rmse))\n",
    "            \n",
    "        return epoch_loss_list, epoch_test_RMSE_list\n",
    "        \n",
    "    def predict(self):\n",
    "        prediction_mat = np.matmul(self.P, self.Q.T)\n",
    "        return prediction_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train an MF model based on your implementation. The code is provided, you just need to excute the next cell. The expectations are: \n",
    "\n",
    "* first, the code can be successfully excuted without error; \n",
    "* and second, the training loss and RMSE on **test_mat** of each training epoch should be printed out for all 20 epochs.\n",
    "\n",
    "\n",
    "* Hint: the expected time used for training is around 10s to 60s per training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:07<02:26,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1, Training Loss=612184.7395222151, Testing RMSE=0.9525733893419833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:15<02:21,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=2, Training Loss=599510.3242672967, Testing RMSE=0.9485357989312708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:23<02:14,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=3, Training Loss=589496.7112731738, Testing RMSE=0.9459597794076539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:31<02:06,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=4, Training Loss=570051.2579950962, Testing RMSE=0.9359915743185577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:39<01:59,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=5, Training Loss=554777.6785265176, Testing RMSE=0.9302376059481375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:47<01:51,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=6, Training Loss=544967.0566916006, Testing RMSE=0.9279634000929288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:55<01:43,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=7, Training Loss=540217.8329264732, Testing RMSE=0.9275586874991552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [01:03<01:35,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=8, Training Loss=532668.6631665917, Testing RMSE=0.9237576390475967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [01:11<01:27,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=9, Training Loss=531685.6355495546, Testing RMSE=0.9255921420256782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [01:19<01:19,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=10, Training Loss=527539.090182081, Testing RMSE=0.9239508972441539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [01:27<01:11,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=11, Training Loss=523458.3373317473, Testing RMSE=0.9216070007938351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [01:35<01:03,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=12, Training Loss=525181.9837498342, Testing RMSE=0.9244999532003632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:43<00:55,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=13, Training Loss=525384.6344363149, Testing RMSE=0.9254395389019967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:51<00:47,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=14, Training Loss=525127.1052172797, Testing RMSE=0.9269071331223984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [01:59<00:40,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=15, Training Loss=526580.8747418381, Testing RMSE=0.9278826571969805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [02:07<00:32,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=16, Training Loss=536127.7202594015, Testing RMSE=0.9368700637081927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [02:15<00:24,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=17, Training Loss=535556.3707597774, Testing RMSE=0.935874054119683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [02:23<00:16,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=18, Training Loss=539569.9021688164, Testing RMSE=0.9408076267390577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [02:31<00:07,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=19, Training Loss=547337.1865426586, Testing RMSE=0.9459944659836795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:39<00:00,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=20, Training Loss=550757.8743181553, Testing RMSE=0.949858392307092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mf = MF(train_mat, test_mat, latent=5, lr=0.01, reg=0.001)\n",
    "epoch_loss_list, epoch_test_RMSE_list = mf.train(epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
